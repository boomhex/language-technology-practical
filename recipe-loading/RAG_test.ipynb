{"cells":[{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["200 recipes loaded.\n"]}],"source":["import os\n","from typing import List, Dict\n","\n","def load_recipes(base_dir: str = \"data\", max_index: int = 200) -> List[Dict]:\n","    \"\"\"\n","    Load recipes from base_dir/i/data.txt for i in [0, max_index].\n","    Each loaded recipe is a dict with an id, title and text.\n","    \"\"\"\n","    docs = []\n","    for i in range(max_index):  # 0..200\n","        recipe_dir = os.path.join(base_dir, str(i))\n","        recipe_path = os.path.join(recipe_dir, \"data.txt\")\n","\n","        if not os.path.exists(recipe_path):\n","            # Skip missing indices gracefully\n","            print(f\"Warning: {recipe_path} not found, skipping.\")\n","            continue\n","\n","        with open(recipe_path, \"r\", encoding=\"utf-8\") as f:\n","            text = f.read()\n","\n","        docs.append(\n","            {\n","                \"id\": str(i),\n","                \"title\": f\"recipe_{i}\",\n","                \"text\": text,\n","                \"path\": recipe_path,\n","            }\n","        )\n","    return docs\n","\n","\n","recipes = load_recipes(\"../model/data\")\n","print(len(recipes), \"recipes loaded.\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1908 chunks total.\n"]}],"source":["def chunk_text_chars(text: str, max_chars: int = 500, overlap: int = 50):\n","    chunks = []\n","    n = len(text)\n","    start = 0\n","    iteration = 0\n","\n","    while start < n:\n","        iteration += 1\n","        end = min(n, start + max_chars)\n","\n","        chunk = text[start:end]\n","        chunks.append(chunk)\n","\n","        # If we reached the end of the text, stop now\n","        if end >= n:\n","            break\n","\n","        # Calculate tentative next start\n","        next_start = end - overlap\n","        # Safety check to avoid infinite loop\n","        if next_start <= start:\n","            next_start = end\n","\n","        # Move to next window\n","        start = next_start\n","    return chunks\n","\n","def build_recipe_chunks(recipes):\n","    \"\"\"\n","    For each recipe document, create smaller chunks.\n","    \"\"\"\n","    chunks = []\n","    for doc in recipes:\n","        text = doc[\"text\"]\n","        for i, chunk in enumerate(chunk_text_chars(text, max_chars=500, overlap=50)):\n","            chunks.append(\n","                {\n","                    \"doc_id\": doc[\"id\"],\n","                    \"chunk_id\": f'{doc[\"id\"]}_chunk_{i}',\n","                    \"title\": doc[\"title\"],\n","                    \"text\": chunk,\n","                }\n","            )\n","    return chunks\n","\n","recipe_chunks = build_recipe_chunks(recipes)\n","print(len(recipe_chunks), \"chunks total.\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentence-transformers in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (5.1.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (4.57.3)\n","Requirement already satisfied: tqdm in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (2.9.1)\n","Requirement already satisfied: scikit-learn in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (1.7.2)\n","Requirement already satisfied: scipy in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (1.16.3)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (0.36.0)\n","Requirement already satisfied: Pillow in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (12.0.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: filelock in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.5)\n","Requirement already satisfied: packaging>=20.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n","Requirement already satisfied: requests in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n","Requirement already satisfied: jinja2 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n","Requirement already satisfied: joblib>=1.2.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install sentence-transformers"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import numpy as np\n","from numpy.linalg import norm\n","from sentence_transformers import SentenceTransformer\n","\n","# Global models / arrays (for simplicity)\n","embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # small, fast\n","\n","def build_embeddings(recipe_chunks):\n","    \"\"\"\n","    Compute embeddings for all chunks.\n","    Returns a NumPy array of shape (num_chunks, embedding_dim).\n","    \"\"\"\n","    texts = [c[\"text\"] for c in recipe_chunks]\n","    emb = embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n","    return emb\n","\n","def embed_query(query: str):\n","    return embed_model.encode([query], convert_to_numpy=True)[0]\n","\n","def retrieve_top_k(query: str, recipe_chunks, embeddings, k: int = 5):\n","    \"\"\"\n","    Given a question, return the top-k most similar chunks.\n","    \"\"\"\n","    q = embed_query(query)\n","    sims = embeddings @ q / (norm(embeddings, axis=1) * norm(q) + 1e-10)\n","    top_idx = np.argsort(-sims)[:k]\n","    results = []\n","    for idx in top_idx:\n","        results.append(\n","            {\n","                \"score\": float(sims[idx]),\n","                \"chunk\": recipe_chunks[idx],\n","            }\n","        )\n","    return results"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 60/60 [00:08<00:00,  7.15it/s]"]},{"name":"stdout","output_type":"stream","text":["Embeddings shape: (1908, 384)\n","score=0.795  title=recipe_67\n","score=0.748  title=recipe_67\n","score=0.728  title=recipe_67\n","score=0.710  title=recipe_67\n","score=0.707  title=recipe_67\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["embeddings = build_embeddings(recipe_chunks)\n","print(\"Embeddings shape:\", embeddings.shape)\n","\n","hits = retrieve_top_k(\"Tofu\", recipe_chunks, embeddings, k=5)\n","\n","for h in hits:\n","    print(f\"score={h['score']:.3f}  title={h['chunk']['title']}\")"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
