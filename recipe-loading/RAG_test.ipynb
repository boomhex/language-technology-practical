{"cells":[{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","import string\n","\n","def remove_interpunction(text: str) -> str:\n","    exclude = set(string.punctuation)\n","    return ''.join(ch for ch in text if ch not in exclude)\n","\n","def fix_whitespace(text: str) -> str:\n","    return ' '.join(text.split())\n","\n","def read_file(path: Path) -> str:\n","    with open(path, 'r') as file:\n","        content = file.read()\n","    return content\n","\n","def normalize_text(text: str) -> str:\n","    text = remove_interpunction(text)\n","    text = fix_whitespace(text)\n","    text = text.lower()\n","    return text"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["200 recipes loaded.\n"]}],"source":["import os\n","from typing import List, Dict\n","\n","def load_recipes(base_dir: str = \"data\", max_index: int = 200) -> List[Dict]:\n","    \"\"\"\n","    Load recipes from base_dir/i/data.txt for i in [0, max_index].\n","    Each loaded recipe is a dict with an id, title and text.\n","    \"\"\"\n","    docs = []\n","    for i in range(max_index):  # 0..200\n","        recipe_path = os.path.join(base_dir, f\"{i}.txt\")\n","\n","        if not os.path.exists(recipe_path):\n","            # Skip missing indices gracefully\n","            print(f\"Warning: {recipe_path} not found, skipping.\")\n","            continue\n","\n","        with open(recipe_path, \"r\", encoding=\"utf-8\") as f:\n","            text = f.read()\n","            text = normalize_text(text)\n","\n","        docs.append(\n","            {\n","                \"id\": str(i),\n","                \"title\": f\"recipe_{i}\",\n","                \"text\": text,\n","                \"path\": recipe_path,\n","            }\n","        )\n","    return docs\n","\n","\n","recipes = load_recipes(\"../model/data\")\n","print(len(recipes), \"recipes loaded.\")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1832 chunks total.\n"]}],"source":["def chunk_text_chars(text: str, max_chars: int = 500, overlap: int = 50):\n","    chunks = []\n","    n = len(text)\n","    start = 0\n","    iteration = 0\n","\n","    while start < n:\n","        iteration += 1\n","        end = min(n, start + max_chars)\n","\n","        chunk = text[start:end]\n","        chunks.append(chunk)\n","\n","        # If we reached the end of the text, stop now\n","        if end >= n:\n","            break\n","\n","        # Calculate tentative next start\n","        next_start = end - overlap\n","        # Safety check to avoid infinite loop\n","        if next_start <= start:\n","            next_start = end\n","\n","        # Move to next window\n","        start = next_start\n","    return chunks\n","\n","def build_recipe_chunks(recipes):\n","    \"\"\"\n","    For each recipe document, create smaller chunks.\n","    \"\"\"\n","    chunks = []\n","    for doc in recipes:\n","        text = doc[\"text\"]\n","        for i, chunk in enumerate(chunk_text_chars(text, max_chars=500, overlap=50)):\n","            chunks.append(\n","                {\n","                    \"doc_id\": doc[\"id\"],\n","                    \"chunk_id\": f'{doc[\"id\"]}_chunk_{i}',\n","                    \"title\": doc[\"title\"],\n","                    \"text\": chunk,\n","                }\n","            )\n","    return chunks\n","\n","recipe_chunks = build_recipe_chunks(recipes)\n","print(len(recipe_chunks), \"chunks total.\")"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentence-transformers in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (5.1.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (4.57.3)\n","Requirement already satisfied: tqdm in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (2.9.1)\n","Requirement already satisfied: scikit-learn in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (1.7.2)\n","Requirement already satisfied: scipy in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (1.16.3)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (0.36.0)\n","Requirement already satisfied: Pillow in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (12.0.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: filelock in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.5)\n","Requirement already satisfied: packaging>=20.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n","Requirement already satisfied: requests in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n","Requirement already satisfied: jinja2 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n","Requirement already satisfied: joblib>=1.2.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/rubenkorbeeck/Desktop/Language Technology Practical/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install sentence-transformers"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["import numpy as np\n","from numpy.linalg import norm\n","from sentence_transformers import SentenceTransformer\n","\n","# Global models / arrays (for simplicity)\n","embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # small, fast\n","\n","def build_embeddings(recipe_chunks):\n","    \"\"\"\n","    Compute embeddings for all chunks.\n","    Returns a NumPy array of shape (num_chunks, embedding_dim).\n","    \"\"\"\n","    texts = [c[\"text\"] for c in recipe_chunks]\n","    emb = embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n","    return emb\n","\n","def embed_query(query: str):\n","    return embed_model.encode([query], convert_to_numpy=True)[0]\n","\n","def retrieve_top_k(query: str, recipe_chunks, embeddings, k: int = 5):\n","    \"\"\"\n","    Given a question, return the top-k most similar chunks.\n","    \"\"\"\n","    q = embed_query(query)\n","    sims = embeddings @ q / (norm(embeddings, axis=1) * norm(q) + 1e-10)\n","    top_idx = np.argsort(-sims)[:k]\n","    results = []\n","    for idx in top_idx:\n","        results.append(\n","            {\n","                \"score\": float(sims[idx]),\n","                \"chunk\": recipe_chunks[idx],\n","            }\n","        )\n","    return results"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Batches: 100%|██████████| 58/58 [00:06<00:00,  9.24it/s]"]},{"name":"stdout","output_type":"stream","text":["Embeddings shape: (1832, 384)\n","score=0.255  title=recipe_113\n","score=0.224  title=recipe_100\n","score=0.183  title=recipe_100\n","score=0.181  title=recipe_100\n","score=0.171  title=recipe_39\n","score=0.169  title=recipe_115\n","score=0.165  title=recipe_63\n","score=0.159  title=recipe_161\n","score=0.158  title=recipe_161\n","score=0.157  title=recipe_39\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["embeddings = build_embeddings(recipe_chunks)\n","print(\"Embeddings shape:\", embeddings.shape)\n","\n","hits = retrieve_top_k(\"\", recipe_chunks, embeddings, k=10)\n","\n","for h in hits:\n","    print(f\"score={h['score']:.3f}  title={h['chunk']['title']}\")"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n","\n","class GenerativeQA:\n","    def __init__(self, device: str = \"cpu\", model_name: str = \"google/flan-t5-small\") -> None:\n","        device_obj = torch.device(device if torch.cuda.is_available() else \"cpu\")\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device_obj)\n","\n","        self.pipe = pipeline(\n","            \"text2text-generation\",\n","            model=self.model,\n","            tokenizer=self.tokenizer,\n","            device=0 if device_obj.type == \"cuda\" else -1,\n","        )\n","\n","    def answer(self, question: str, contexts: list[str]) -> str:\n","        \"\"\"\n","        Answer a question given a list of retrieved context chunks.\n","        \"\"\"\n","        joined_context = \"\\n\\n\".join(contexts)\n","\n","        prompt = (\n","            \"You are an assistant that answers questions about recipes.\\n\"\n","            \"Use only the information in the context. \"\n","            \"If the answer is not in the context, say you don't know.\\n\\n\"\n","            f\"Context:\\n{joined_context}\\n\\n\"\n","            f\"Question: {question}\\n\\n\"\n","            \"Answer:\"\n","        )\n","\n","        out = self.pipe(\n","            prompt,\n","            max_new_tokens=128,\n","            num_beams=4,\n","            do_sample=False,\n","            truncation=True,\n","        )[0][\"generated_text\"]\n","        return out.strip()"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def ask_recipe_question(gen_qa: GenerativeQA,\n","                        question: str,\n","                        recipe_chunks,\n","                        embeddings,\n","                        k_retrieval: int = 5):\n","    # 1. retrieve top-k relevant chunks\n","    hits = retrieve_top_k(question, recipe_chunks, embeddings, k=k_retrieval)\n","    contexts = [h[\"chunk\"][\"text\"] for h in hits]\n","\n","    # 2. generate answer\n","    answer = gen_qa.answer(question, contexts)\n","    return answer, hits"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["q = input(\"\\nAsk a question about your recipes (or type 'quit'): \").strip()\n","\n","\n","answer, hits = ask_recipe_question(gen_qa, q, recipe_chunks, embeddings, k_retrieval=5)\n","\n","print(\"\\nAnswer:\")\n","print(answer)\n","\n","print(\"\\nTop retrieved recipe chunks:\")\n","for h in hits[:3]:\n","    print(f\"- Recipe {h['chunk']['doc_id']} ({h['chunk']['title']}), score={h['score']:.3f}\")\n","print(\"-\" * 60)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
